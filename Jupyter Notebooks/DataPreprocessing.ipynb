{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPj2yuFSCw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UNCOMMENT IF USING COLAB\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JUv-o34UqVY",
        "colab_type": "code",
        "outputId": "9968ae6a-c141-4c04-828b-b42c45dcc86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# LOADS 3 FILES\n",
        "#     1. 311_06.csv -> contains 311 Public complaints data from New York City\n",
        "#     2. CrimeData.csv -> Multi-year crime records\n",
        "#     3. Regions.csv -> Geographical divisions of the city into precincts\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shapely.wkt\n",
        "from shapely.geometry import Point, Polygon, MultiPolygon\n",
        "\n",
        "# Change the 'year' and file locations according to your dataset\n",
        "year = '2006'\n",
        "file311 = \"RawData/311_06.csv\"\n",
        "fileCrime = \"RawData/CrimeData.csv\"\n",
        "fileRegions = \"RawData/Regions.csv\"\n",
        "\n",
        "# Extract:\n",
        "#     1. Relevant columns\n",
        "#     2. Relevant types of complaints, from the 'Complaint Type' column\n",
        "\n",
        "data311 = pd.read_csv(file311,low_memory=False)\n",
        "relevantColumns311 = ['Created Date','Latitude','Longitude','Complaint Type']\n",
        "relevantComplaints311 = ['Blocked Driveway','Building/Use','Noise','Safety']\n",
        "finalColumns311 = ['Created Date','Complaint Type','Precincts']\n",
        "data311 = data311[relevantColumns311]\n",
        "data311 = data311.loc[(data311['Complaint Type'] == 'Blocked Driveway') | (data311['Complaint Type'] == 'Building/Use') | (data311['Complaint Type'] == 'Noise') | (data311['Complaint Type'] == 'Safety')]\n",
        "print('Anomalies preprocessed!!!')\n",
        "\n",
        "# Extract:\n",
        "#     1. Relevant columns\n",
        "#     2. Relevant types of crimes, from the 'OFNS_DESC' column\n",
        "\n",
        "crimeData = pd.read_csv(fileCrime, low_memory=False)\n",
        "relevantColumnsCR = ['CMPLNT_TO_DT','CMPLNT_TO_TM','CMPLNT_FR_DT','RPT_DT','Lat_Lon','Latitude','Longitude','OFNS_DESC']\n",
        "finalColumnsCR = ['Date','OFNS_DESC','CMPLNT_TO_TM','Longitude','Latitude','Precincts']\n",
        "relevantCrimesCR = ['ROBBERY', 'BURGLARY', 'FELONY ASSAULT','GRAND LARCENY']\n",
        "locations = pd.read_csv(\"RawData/Regions.csv\", low_memory=False)\n",
        "crime2006 = crimeData.loc[crimeData['RPT_DT'].str.endswith(year)]\n",
        "crime2006 = crime2006[relevantColumnsCR]\n",
        "crime2006 = crime2006.loc[(crime2006['OFNS_DESC'] == 'ROBBERY') | (crime2006['OFNS_DESC'] == 'BURGLARY') | (crime2006['OFNS_DESC'] == 'FELONY ASSAULT') | (crime2006['OFNS_DESC'] == 'GRAND LARCENY')]\n",
        "print('Crime Preprocessed!!!')\n",
        "\n",
        "# Load the regions and store a MultiPolygon object(corresponding to the geometry of the region) and the precinct number\n",
        "\n",
        "locations = pd.read_csv(fileRegions, low_memory=False)\n",
        "precincts = {}\n",
        "for index, row in locations.iterrows():\n",
        "  precincts[row['Precinct']] = shapely.wkt.loads(row['the_geom'])\n",
        "\n",
        "print('Locations loaded!!!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anomalies preprocessed!!!\n",
            "Crime Preprocessed!!!\n",
            "Locations loaded!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ70JHNMJKpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracts the latitude/longitude information of each 311 complaint reported\n",
        "# And assigns it to one of the precincts defined earlier in form of a MultiPolygon\n",
        "\n",
        "pos = 0\n",
        "prec = np.ndarray((data311.shape[0],))\n",
        "\n",
        "for index,row in data311.iterrows():\n",
        "\n",
        "  poo = Point(row['Longitude'],row['Latitude'])  \n",
        "  for key,val in precincts.items():\n",
        "    if poo.within(val):\n",
        "      prec[pos] = key\n",
        "      break\n",
        "\n",
        "  pos=pos+1\n",
        "  if(pos%1000 == 0):\n",
        "    print (\"processed \"+str(pos)+\" records!!\")\n",
        "\n",
        "# Adds the precincts information to the dataset\n",
        "data311['Precincts'] = prec.astype(int)\n",
        "print(\"Done!!\")\n",
        "\n",
        "# Extract the final columns needed for training the model\n",
        "data311['Precincts'] = data311['Precincts'].astype(np.int64)\n",
        "data311 = data311[data311['Precincts'] >= 0]\n",
        "data311 = data311[finalColumns311]\n",
        "\n",
        "print('Anomaly Preprocessing complete!!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdR_e170WZiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracts the latitude/longitude information of each crime reported\n",
        "# And assigns it to one of the precincts defined earlier in form of a MultiPolygon\n",
        "\n",
        "# Also, some preprocessing is done on the date columns as well\n",
        "# To ensure that the final date column doesn't have NaN values\n",
        "\n",
        "pos = 0\n",
        "prec = np.ndarray((crime2006.shape[0],))\n",
        "date = np.ndarray((crime2006.shape[0],)).astype(str)\n",
        "\n",
        "for index,row in crime2006.iterrows():\n",
        "  \n",
        "  if not(str(row['CMPLNT_FR_DT']) == 'nan'):\n",
        "    date[pos] = row['CMPLNT_FR_DT']\n",
        "  elif not(str(row['CMPLNT_TO_DT']) == 'nan'):\n",
        "    date[pos] = row['CMPLNT_TO_DT']\n",
        "  else:\n",
        "    date[pos] = row['RPT_DT']\n",
        "  \n",
        "  poo = Point(row['Longitude'],row['Latitude'])  \n",
        "  for key,val in precincts.items():\n",
        "    if poo.within(val):\n",
        "      prec[pos] = key\n",
        "      break\n",
        "\n",
        "  pos=pos+1\n",
        "  if(pos%1000 == 0):\n",
        "    print (\"processed \"+str(pos)+\" records!!\")\n",
        "\n",
        "# Adds the precincts information to the dataset\n",
        "# Adds the dates information to the dataset\n",
        "\n",
        "crime2006['Precincts'] = prec.astype(int)\n",
        "crime2006['Date'] = date\n",
        "crime2006 = crime2006[crime2006['Precincts'] >= 0]\n",
        "\n",
        "print(\"Done!!\")\n",
        "\n",
        "# Extract the final columns needed for training the model\n",
        "crime2006 = crime2006[finalColumnsCR]\n",
        "crime2006.sort_values(['Precincts','Date','OFNS_DESC'],ascending=[True,True,True],inplace=True)\n",
        "crime2006 = crime2006[crime2006['Date'].str.contains(year)]\n",
        "crime2006['Precincts'] = crime2006['Precincts'].astype(np.int64)\n",
        "\n",
        "print('Crime Preprocessing complete!!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWknfNTtU9Dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates inverted dictionaries for\n",
        "#     1. Date for the particular year, according to the 'year' var defined earlier\n",
        "#     2. Complaints: according to the 4 categories that we are considering\n",
        "#     3. Precincts: the grographical divisions of the city\n",
        "#     4. Crimes: according to the 4 categories we are considering for prediction\n",
        "\n",
        "# The final input that we feed to the Heirarchical LSTMs is in form of matrices\n",
        "# These inverted indices help in conversion of the dataframe to thse matrices\n",
        "\n",
        "daterange = pd.date_range(start='01/01/'+year,end='12/31/'+year)\n",
        "daterange = daterange.strftime('%m/%d/%Y')\n",
        "daterange = daterange.tolist()\n",
        "\n",
        "inv_dict = {}\n",
        "for i in range(len(daterange)):\n",
        "  inv_dict[daterange[i]] = i\n",
        "\n",
        "inv_complaints = {}\n",
        "for i in range(len(relevantComplaints311)):\n",
        "  inv_complaints[relevantComplaints311[i]] = i\n",
        "\n",
        "n_precincts = data311['Precincts'].nunique()\n",
        "uniq_precincts = data311['Precincts'].unique()\n",
        "inv_prec = {}\n",
        "for i in range(n_precincts):\n",
        "  inv_prec[uniq_precincts[i]] = i\n",
        "\n",
        "inv_crimes = {}\n",
        "for i in range(len(relevantCrimesCR)):\n",
        "  inv_crimes[relevantCrimesCR[i]] = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2ec1hJVWxXO",
        "colab_type": "code",
        "outputId": "b8e28a4e-3503-4187-8ab0-0d429af7cf7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Generate the matrices for Crime (365x78x4) and 311 Complaints (365x78x4)\n",
        "# Here the 2nd dimension represents the precinct and is 78, instead of 77\n",
        "# This is because all the complaints/crimes with no geographical location have been assigned 0th position\n",
        "# This 0th position is later discarded during the training process, but can be used if one wishes to do so\n",
        "\n",
        "# Each matrix represents crime/complaint occurence over different categories(4), over different localities(78) over a period of 1 year(365)\n",
        "\n",
        "\n",
        "# Generating the crime records matrices\n",
        "matricesCR = [np.zeros((n_precincts,4),dtype=np.int64) for x in range(365)]\n",
        "exceptions = 0\n",
        "\n",
        "for idx, row in crime2006.iterrows():\n",
        "  try:\n",
        "    id1 = inv_prec[row['Precincts']]\n",
        "    id2 = inv_dict[row['Date']]\n",
        "    id3 = inv_crimes[row['OFNS_DESC']]\n",
        "    matricesCR[id2][id1][id3] = matricesCR[id2][id1][id3] + 1\n",
        "  except:\n",
        "    print(\"Exception!!!\")\n",
        "    print(\"Precincts\",id1)\n",
        "    print(\"Date\",id2)\n",
        "    print(\"Offense\",id3)\n",
        "    exceptions = exceptions + 1\n",
        "\n",
        "print ('Created crime matrices!!!')\n",
        "\n",
        "# Generating the 311 complaints records matrices\n",
        "matrices311 = [np.zeros((n_precincts,4),dtype=np.int64) for x in range(365)]\n",
        "exceptions = 0\n",
        "\n",
        "for idx, row in data311.iterrows():\n",
        "  try:\n",
        "    id1 = inv_prec[row['Precincts']]\n",
        "    id2 = inv_dict[str(row['Created Date']).split()[0]]\n",
        "    id3 = inv_complaints[row['Complaint Type']]\n",
        "    matrices311[id2][id1][id3] = matrices311[id2][id1][id3] + 1\n",
        "  except:\n",
        "    print(\"Exception!!!\")\n",
        "    print(\"Precincts\",id1)\n",
        "    print(\"Date\",id2)\n",
        "    print(\"Offense\",id3)\n",
        "    exceptions = exceptions + 1\n",
        "\n",
        "print('Created anomaly matrices!!!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created crime matrices!!!\n",
            "Created anomaly matrices!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47hlZc9naCK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "# Dump the matrices using pickle, to a file\n",
        "output311 = 'matrices311'\n",
        "outputCrime = 'matricesCR'\n",
        "\n",
        "file311 = open(output311,'wb')\n",
        "pickle.dump(matrices311,file311)\n",
        "\n",
        "fileCR = open(outputCrime,'wb')\n",
        "pickle.dump(matricesCR,fileCR)\n",
        "\n",
        "# To load these files, use:\n",
        "# with open(filename,'rb') as toOpen:\n",
        "#     data = pickle.load(toOpen)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}